{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> <b> Data Collecting </b></p>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nest_asyncio\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply() \n",
    "session = HTMLSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘‰ Crawl the first 5000 urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 urls collected\r"
     ]
    }
   ],
   "source": [
    "listUrl1 = []\n",
    "\n",
    "for i in range(0, 5000, 50):\n",
    "    # Url of the website to scrap\n",
    "    url = f'https://myanimelist.net/topmanga.php?limit={i}'\n",
    "\n",
    "    # Get the html content\n",
    "    html = requests.get(url).text\n",
    "\n",
    "    # Parse the html content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Get the list of manga\n",
    "    listItem = soup.find_all(\"td\", {\"class\": \"title al va-t clearfix word-break\"})\n",
    "\n",
    "    # Get the url of each manga\n",
    "    for item in listItem:\n",
    "        listUrl1.append(item.find('a').get('href'))\n",
    "\n",
    "    # Print the number of manga urls collected\n",
    "    print(f'{len(listUrl1)} urls collected', end='\\r', flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘‰ Crawl the remaining 5000 urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similar to data collection above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000 urls collected\n"
     ]
    }
   ],
   "source": [
    "listUrl2 = []\n",
    "\n",
    "for i in range(5000,10000,50):\n",
    "    # Url of the website to scrap\n",
    "    url = f'https://myanimelist.net/topmanga.php?limit={i}'\n",
    "\n",
    "    # Get the html content\n",
    "    html = requests.get(url).text\n",
    "\n",
    "    # Parse the html content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Get the list of manga\n",
    "    listItem = soup.find_all(\"td\", {\"class\": \"title al va-t clearfix word-break\"})\n",
    "\n",
    "    # Get the url of each manga\n",
    "    for item in listItem:\n",
    "        listUrl2.append(item.find('a').get('href'))\n",
    "\n",
    "    # Print the number of manga urls collected\n",
    "    print(f'{len(listUrl2)} urls collected', end='\\r', flush=True)\n",
    "    \n",
    "listUrl = listUrl1 + listUrl2\n",
    "print(f'Total: {len(listUrl)} urls collected')\n",
    "with open('listUrl_manga.txt', 'w') as f:\n",
    "    for url in listUrl:\n",
    "        f.write(\"%s\\n\" % url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘‰ Concatenate 2 list urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 urls collected\r"
     ]
    }
   ],
   "source": [
    "listUrl1 = []\n",
    "\n",
    "for i in range(0, 5000, 50):\n",
    "    url = f'https://myanimelist.net/topanime.php?limit={i}'\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    listItem = soup.find_all(\"td\", {\"class\": \"title al va-t word-break\"})\n",
    "\n",
    "    for item in listItem:\n",
    "        listUrl1.append(item.find('a').get('href'))\n",
    "\n",
    "    # Print the number of manga urls collected\n",
    "    print(f'{len(listUrl1)} urls collected', end='\\r', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000 urls collected\n"
     ]
    }
   ],
   "source": [
    "listUrl2 = []\n",
    "\n",
    "for i in range(5000,10000,50):\n",
    "    # Url of the website to scrap\n",
    "    url = f'https://myanimelist.net/topanime.php?limit={i}'\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    listItem = soup.find_all(\"td\", {\"class\": \"title al va-t word-break\"})\n",
    "\n",
    "    for item in listItem:\n",
    "        listUrl2.append(item.find('a').get('href'))\n",
    "\n",
    "    print(f'{len(listUrl2)} urls collected', end='\\r', flush=True)\n",
    "    \n",
    "listUrl = listUrl1 + listUrl2\n",
    "print(f'Total: {len(listUrl)} urls collected')\n",
    "with open('listUrl_anime.txt', 'w') as f:\n",
    "    for url in listUrl:\n",
    "        f.write(\"%s\\n\" % url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘‰ Crawl HTML content from the first 5000 manga URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/10000 manga html collected\r"
     ]
    }
   ],
   "source": [
    "manga_url1 = []\n",
    "with open('listUrl_manga.txt', 'r') as f:\n",
    "    listUrl = f.read().splitlines()\n",
    "\n",
    "for url in listUrl[:5000]:\n",
    "    res = session.get(url)\n",
    "    while len(res.text) < 4000:\n",
    "        # Sleep for 10 minutes\n",
    "        time.sleep(600)\n",
    "        res = session.get(url)\n",
    "        \n",
    "    manga_url1.append(res.text)\n",
    "\n",
    "    # Print the number of manga html collected\n",
    "    print(f'{len(manga_url1)}/{len(listUrl)} manga html collected', end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘‰ Crawl HTML content from the remaining 5000 manga URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('manga_html1.txt', 'w') as f:\n",
    "    for manga in manga_url1:\n",
    "        f.write(\"%s\\n\" % manga)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 manga html collected\r"
     ]
    }
   ],
   "source": [
    "manga_url2 = []\n",
    "\n",
    "for url in listUrl[5000:]:\n",
    "    res = session.get(url)\n",
    "    while len(res.text) < 4000:\n",
    "        # Sleep for 10 minutes\n",
    "        time.sleep(600)\n",
    "        res = session.get(url)\n",
    "        \n",
    "    manga_url2.append(res.text)\n",
    "\n",
    "    # Print the number of manga html collected\n",
    "    print(f'{len(manga_url2)+5000}/{len(listUrl)} manga html collected', end='\\r', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('manga_html2.txt', 'w') as f:\n",
    "    for manga in manga_url2:\n",
    "        f.write(\"%s\\n\" % manga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/10000 anime html collected\r"
     ]
    }
   ],
   "source": [
    "anime_url1 = []\n",
    "with open('listUrl_anime.txt', 'r') as f:\n",
    "    listUrl = f.read().splitlines()\n",
    "\n",
    "for url in listUrl[:5000]:\n",
    "    res = session.get(url)\n",
    "    while len(res.text) < 4000:\n",
    "        # Sleep for 10 minutes\n",
    "        time.sleep(600)\n",
    "        res = session.get(url)\n",
    "        \n",
    "    anime_url1.append(res.text)\n",
    "\n",
    "    # Print the number of manga html collected\n",
    "    print(f'{len(anime_url1)}/{len(listUrl)} anime html collected', end='\\r', flush=True)\n",
    "    \n",
    "with open('anime_html1.txt', 'w') as f:\n",
    "    for anime in anime_url1:\n",
    "        f.write(\"%s\\n\" % anime)\n",
    "        f.write('========\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listUrl_anime.txt', 'r') as f:\n",
    "    listUrl = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 anime html collected\r"
     ]
    }
   ],
   "source": [
    "anime_url2 = []\n",
    "\n",
    "for url in listUrl[:5000]:\n",
    "    res = session.get(url)\n",
    "    while len(res.text) < 4000:\n",
    "        # Sleep for 10 minutes\n",
    "        time.sleep(1000)\n",
    "        res = session.get(url)\n",
    "        \n",
    "    anime_url2.append(res.text)\n",
    "\n",
    "    # Print the number of manga html collected\n",
    "    print(f'{len(anime_url2)+5000}/{len(listUrl)} anime html collected', end='\\r', flush=True)\n",
    "    \n",
    "with open('anime_html2.txt', 'w') as f:\n",
    "    for anime in anime_url2:\n",
    "        f.write(\"%s\\n\" % anime)\n",
    "        f.write(\"========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of data collection:  2023-12-05\n"
     ]
    }
   ],
   "source": [
    "# Extract time of data collection to report for the project\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d\")\n",
    "print(\"Time of data collection: \", now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘‰ Concatenate 2 list htmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000 manga html collected\n"
     ]
    }
   ],
   "source": [
    "manga_url = manga_url1 + manga_url2\n",
    "print(f'Total: {len(manga_url)} manga html collected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000 anime html collected\n"
     ]
    }
   ],
   "source": [
    "anime_url = anime_url1 + anime_url2\n",
    "print(f'Total: {len(anime_url)} anime html collected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘‰ Extracting the detailed values of each comic website page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_manga(htmlComic):\n",
    "    soup = BeautifulSoup(htmlComic, \"html.parser\")\n",
    "\n",
    "    title = soup.find('span', {'itemprop': 'name'})\n",
    "    if title is None:\n",
    "        return None\n",
    "    else:\n",
    "        title_text = title.text.strip()\n",
    "        title_english_span = title.find('span', {'class': 'title-english'})\n",
    "\n",
    "        if title_english_span is not None:\n",
    "            title_english_text = title_english_span.text.strip()\n",
    "            title_text = title_text.replace(title_english_text, '')\n",
    "            title = f'{title_text} ({title_english_text})'\n",
    "        else:\n",
    "            title = title_text\n",
    "    ratingValue = soup.find('span', {'itemprop': 'ratingValue'}).text\n",
    "    ratingCount = soup.find('span', {'itemprop': 'ratingCount'}).text\n",
    "    ranked = re.findall(r'\\d+', soup.find('span', {'class': 'numbers ranked'}).text)[0]\n",
    "    popularity = re.findall(r'\\d+', soup.find('span', {'class': 'numbers popularity'}).text)[0]\n",
    "\n",
    "    volumes, chapters, status, published = '', '', '', ''\n",
    "    genres, themes,demographics, serialization,authors, favorites, members = [], [], [],'', '', '',''\n",
    "    \n",
    "    for space in soup.find_all(\"div\", {'class': 'spaceit_pad'}):\n",
    "        text = space.text\n",
    "        if 'Volumes' in text:\n",
    "            volumes = text.split(':')[1].strip()\n",
    "        elif 'Chapters' in text:\n",
    "            chapters = text.split(':')[1].strip()\n",
    "        elif 'Status' in text:\n",
    "            status = text.split(':')[1].strip()\n",
    "        elif 'Published' in text:\n",
    "            published = text.split(':')[1].strip()\n",
    "        elif 'Genres' in text:\n",
    "            genres = [gen.text for gen in space.find_all('span', {'itemprop': 'genre'})]\n",
    "        elif 'Themes' in text:\n",
    "            themes = [theme.text for theme in space.find_all('span', {'itemprop': 'genre'})]\n",
    "        elif 'Demographic' in text:\n",
    "            demographics = [demographic.text for demographic in space.find_all('span', {'itemprop': 'genre'})]\n",
    "        elif 'Serialization' in text:\n",
    "            serialization = text.split(':')[1].strip()\n",
    "        elif 'Authors' in text:\n",
    "            authors = text.split(':')[1].strip()\n",
    "        elif 'Favorites' in text:\n",
    "            favorites = text.split(':')[1].strip()\n",
    "        elif 'Members' in text:\n",
    "            members = text.split(':')[1].strip()\n",
    "        \n",
    "\n",
    "\n",
    "    return {\n",
    "        \"Title\": title, \"Score\": ratingValue, \"Vote\": ratingCount,\n",
    "        \"Ranked\": ranked, \"Popularity\": popularity, \"Members\": members,\n",
    "        \"Favorite\": favorites, \"Volumes\": volumes, \"Chapters\": chapters,\n",
    "        \"Status\": status, \"Published\": published, \"Genres\": genres,\n",
    "        \"Themes\": themes, 'Demographics': demographics, 'Serialization': serialization,\n",
    "        \"Author\": authors, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_anime(htmlComic):\n",
    "    soup = BeautifulSoup(htmlComic, \"html.parser\")\n",
    "\n",
    "    title = soup.find('div', {'itemprop': 'name'})\n",
    "    if title is None:\n",
    "        return None\n",
    "    else:\n",
    "        title_text = title.text.strip()\n",
    "        title_english_span = title.find('span', {'class': 'title-english'})\n",
    "\n",
    "        if title_english_span is not None:\n",
    "            title_english_text = title_english_span.text.strip()\n",
    "            title_text = title_text.replace(title_english_text, '')\n",
    "            title = f'{title_text} ({title_english_text})'\n",
    "        else:\n",
    "            title = title_text\n",
    "    ratingValue = soup.find('span', {'itemprop': 'ratingValue'}).text\n",
    "    ratingCount = soup.find('span', {'itemprop': 'ratingCount'}).text\n",
    "    ranked = re.findall(r'\\d+', soup.find('span', {'class': 'numbers ranked'}).text)[0]\n",
    "    popularity = re.findall(r'\\d+', soup.find('span', {'class': 'numbers popularity'}).text)[0]\n",
    "\n",
    "    episodes, status, aired, premiered, producers, licensors, studios, source, duration, rating = '', '', '', '', '', '', '', '', '', ''\n",
    "\n",
    "    for space in soup.find_all(\"div\", {'class': 'spaceit_pad'}):\n",
    "        text = space.text\n",
    "        if 'Episodes' in text:\n",
    "            episodes = text.split(':')[1].strip()\n",
    "        elif 'Status' in text:\n",
    "            status = text.split(':')[1].strip()\n",
    "        elif 'Aired' in text:\n",
    "            aired = text.split(':')[1].strip()\n",
    "        elif 'Premiered' in text:\n",
    "            premiered = text.split(':')[1].strip()\n",
    "        elif 'Producers' in text:\n",
    "            producers = [producer.text for producer in space.find_all('a')]\n",
    "        elif 'Licensors' in text:\n",
    "            licensors = text.split(':')[1].strip()\n",
    "        elif 'Studios' in text:\n",
    "            studios = text.split(':')[1].strip()\n",
    "        elif 'Source' in text:\n",
    "            source = text.split(':')[1].strip()\n",
    "        elif 'Genres' in text:\n",
    "            genres = [gen.text for gen in space.find_all('span', {'itemprop': 'genre'})]\n",
    "        elif 'Demographic' in text:\n",
    "            demographics = [demographic.text for demographic in space.find_all('span', {'itemprop': 'genre'})]\n",
    "        elif 'Duration' in text:\n",
    "            duration = text.split(':')[1].strip()\n",
    "        elif 'Rating' in text:\n",
    "            rating = text.split(':')[1].strip()\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"Title\": title, \"Score\": ratingValue, \"Vote\": ratingCount,\n",
    "        \"Ranked\": ranked, \"Popularity\": popularity, \"Episodes\": episodes,\n",
    "        \"Status\": status, \"Aired\": aired, \"Premiered\": premiered,\n",
    "        \"Producers\": producers, \"Licensors\": licensors, \"Studios\": studios,\n",
    "        \"Source\": source, \"Duration\": duration, \"Rating\": rating\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "manga_data = [extract_manga(html) for html in manga_url]\n",
    "manga_df = pd.DataFrame(manga_data)\n",
    "\n",
    "manga_df.to_csv('./data/manga.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Vote</th>\n",
       "      <th>Ranked</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Members</th>\n",
       "      <th>Favorite</th>\n",
       "      <th>Volumes</th>\n",
       "      <th>Chapters</th>\n",
       "      <th>Status</th>\n",
       "      <th>Published</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Themes</th>\n",
       "      <th>Demographics</th>\n",
       "      <th>Serialization</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>Shinohayu: the Dawn of Age</td>\n",
       "      <td>7.95</td>\n",
       "      <td>360</td>\n",
       "      <td>849</td>\n",
       "      <td>10835</td>\n",
       "      <td>1,508</td>\n",
       "      <td>36</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Jul  25, 2013 to ?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Shounen]</td>\n",
       "      <td>Big Gangan</td>\n",
       "      <td>Igarashi, Aguri (Art), Kobayashi, Ritz (Story)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9199</th>\n",
       "      <td>Hatsukoi Kids Sitter (First Love Kids Sitter)</td>\n",
       "      <td>6.96</td>\n",
       "      <td>101</td>\n",
       "      <td>9225</td>\n",
       "      <td>27954</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Finished</td>\n",
       "      <td>Jul  12, 2022 to Dec  13, 2022</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>B-BOY P!</td>\n",
       "      <td>Kuroda, Kurota (Story &amp; Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>Saihate ni Madou</td>\n",
       "      <td>7.85</td>\n",
       "      <td>1337</td>\n",
       "      <td>1142</td>\n",
       "      <td>2662</td>\n",
       "      <td>7,464</td>\n",
       "      <td>82</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Jan  6, 2023 to ?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Josei]</td>\n",
       "      <td>Flat Hero's</td>\n",
       "      <td>Momoyama, Hato (Story &amp; Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>Risouteki Boyfriend (The World Best Boyfriend)</td>\n",
       "      <td>7.54</td>\n",
       "      <td>1801</td>\n",
       "      <td>2613</td>\n",
       "      <td>3945</td>\n",
       "      <td>5,027</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>Finished</td>\n",
       "      <td>Mar  31, 2016 to Jul  13, 2018</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Shoujo]</td>\n",
       "      <td>Bessatsu Margaret</td>\n",
       "      <td>Ayase, Umi (Story &amp; Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>Kurogane</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1686</td>\n",
       "      <td>5313</td>\n",
       "      <td>6280</td>\n",
       "      <td>2,987</td>\n",
       "      <td>5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>Finished</td>\n",
       "      <td>Dec  20, 2010</td>\n",
       "      <td>[Action, Supernatural]</td>\n",
       "      <td>[Martial Arts, School]</td>\n",
       "      <td>[Shounen]</td>\n",
       "      <td>Shounen Jump (Weekly)</td>\n",
       "      <td>Ikezawa, Haruto (Story &amp; Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>Youchien Wars (Kindergarten Wars)</td>\n",
       "      <td>7.61</td>\n",
       "      <td>2005</td>\n",
       "      <td>2176</td>\n",
       "      <td>2469</td>\n",
       "      <td>7,965</td>\n",
       "      <td>73</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Sep  15, 2022 to ?</td>\n",
       "      <td>[Action, Comedy]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Shounen]</td>\n",
       "      <td>Shounen Jump+</td>\n",
       "      <td>Chiba, Yuu (Story &amp; Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>Arakure Ojousama wa Monmon Shiteiru</td>\n",
       "      <td>7.08</td>\n",
       "      <td>3387</td>\n",
       "      <td>7527</td>\n",
       "      <td>1606</td>\n",
       "      <td>11,997</td>\n",
       "      <td>66</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Nov  6, 2018 to ?</td>\n",
       "      <td>[Comedy, Ecchi]</td>\n",
       "      <td>[Romantic Subtext, School]</td>\n",
       "      <td>[Seinen]</td>\n",
       "      <td>Young Magazine the 3rd</td>\n",
       "      <td>Kinoshita, Yuuichi (Story &amp; Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>Nadeshiko Club</td>\n",
       "      <td>7.32</td>\n",
       "      <td>885</td>\n",
       "      <td>4479</td>\n",
       "      <td>7994</td>\n",
       "      <td>2,241</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2000 to  2003</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "      <td>[Reverse Harem, School]</td>\n",
       "      <td>[Shoujo]</td>\n",
       "      <td>Hana to Yume</td>\n",
       "      <td>Sakamoto, Miku (Story &amp; Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>Genjitsu Shugi Yuusha no Oukoku Saikenki (How ...</td>\n",
       "      <td>7.45</td>\n",
       "      <td>6043</td>\n",
       "      <td>3251</td>\n",
       "      <td>897</td>\n",
       "      <td>19,604</td>\n",
       "      <td>147</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Jul  10, 2017 to ?</td>\n",
       "      <td>[Action, Fantasy]</td>\n",
       "      <td>[Isekai, Military]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Comic Gardo</td>\n",
       "      <td>Ueda, Satoshi (Art), Dozeumaru (Story)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>Zoku - Kindan no Koi wo Shiyou</td>\n",
       "      <td>7.38</td>\n",
       "      <td>1623</td>\n",
       "      <td>3849</td>\n",
       "      <td>6475</td>\n",
       "      <td>2,895</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2001</td>\n",
       "      <td>[Fantasy, Romance]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Josei]</td>\n",
       "      <td>Petit Comic</td>\n",
       "      <td>Ohmi, Tomu (Story &amp; Art)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title Score  Vote Ranked  \\\n",
       "848                          Shinohayu: the Dawn of Age  7.95   360    849   \n",
       "9199      Hatsukoi Kids Sitter (First Love Kids Sitter)  6.96   101   9225   \n",
       "1125                                   Saihate ni Madou  7.85  1337   1142   \n",
       "2594     Risouteki Boyfriend (The World Best Boyfriend)  7.54  1801   2613   \n",
       "5259                                           Kurogane  7.25  1686   5313   \n",
       "2153                  Youchien Wars (Kindergarten Wars)  7.61  2005   2176   \n",
       "7501                Arakure Ojousama wa Monmon Shiteiru  7.08  3387   7527   \n",
       "4479                                     Nadeshiko Club  7.32   885   4479   \n",
       "3318  Genjitsu Shugi Yuusha no Oukoku Saikenki (How ...  7.45  6043   3251   \n",
       "3908                     Zoku - Kindan no Koi wo Shiyou  7.38  1623   3849   \n",
       "\n",
       "     Popularity Members Favorite  Volumes Chapters      Status  \\\n",
       "848       10835   1,508       36  Unknown  Unknown  Publishing   \n",
       "9199      27954     299        0        1        7    Finished   \n",
       "1125       2662   7,464       82  Unknown  Unknown  Publishing   \n",
       "2594       3945   5,027       49        7       29    Finished   \n",
       "5259       6280   2,987        5  Unknown        1    Finished   \n",
       "2153       2469   7,965       73  Unknown  Unknown  Publishing   \n",
       "7501       1606  11,997       66  Unknown  Unknown  Publishing   \n",
       "4479       7994   2,241        4        7       35    Finished   \n",
       "3318        897  19,604      147  Unknown  Unknown  Publishing   \n",
       "3908       6475   2,895       16        1        4    Finished   \n",
       "\n",
       "                           Published                  Genres  \\\n",
       "848               Jul  25, 2013 to ?                      []   \n",
       "9199  Jul  12, 2022 to Dec  13, 2022                      []   \n",
       "1125               Jan  6, 2023 to ?                      []   \n",
       "2594  Mar  31, 2016 to Jul  13, 2018                      []   \n",
       "5259                   Dec  20, 2010  [Action, Supernatural]   \n",
       "2153              Sep  15, 2022 to ?        [Action, Comedy]   \n",
       "7501               Nov  6, 2018 to ?         [Comedy, Ecchi]   \n",
       "4479                   2000 to  2003       [Comedy, Romance]   \n",
       "3318              Jul  10, 2017 to ?       [Action, Fantasy]   \n",
       "3908                            2001      [Fantasy, Romance]   \n",
       "\n",
       "                          Themes Demographics           Serialization  \\\n",
       "848                           []    [Shounen]              Big Gangan   \n",
       "9199                          []           []                B-BOY P!   \n",
       "1125                          []      [Josei]             Flat Hero's   \n",
       "2594                          []     [Shoujo]       Bessatsu Margaret   \n",
       "5259      [Martial Arts, School]    [Shounen]   Shounen Jump (Weekly)   \n",
       "2153                          []    [Shounen]           Shounen Jump+   \n",
       "7501  [Romantic Subtext, School]     [Seinen]  Young Magazine the 3rd   \n",
       "4479     [Reverse Harem, School]     [Shoujo]            Hana to Yume   \n",
       "3318          [Isekai, Military]           []             Comic Gardo   \n",
       "3908                          []      [Josei]             Petit Comic   \n",
       "\n",
       "                                              Author  \n",
       "848   Igarashi, Aguri (Art), Kobayashi, Ritz (Story)  \n",
       "9199                    Kuroda, Kurota (Story & Art)  \n",
       "1125                    Momoyama, Hato (Story & Art)  \n",
       "2594                        Ayase, Umi (Story & Art)  \n",
       "5259                   Ikezawa, Haruto (Story & Art)  \n",
       "2153                        Chiba, Yuu (Story & Art)  \n",
       "7501                Kinoshita, Yuuichi (Story & Art)  \n",
       "4479                    Sakamoto, Miku (Story & Art)  \n",
       "3318          Ueda, Satoshi (Art), Dozeumaru (Story)  \n",
       "3908                        Ohmi, Tomu (Story & Art)  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manga_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data = [extract_anime(html) for html in anime_url]\n",
    "anime_df = pd.DataFrame(anime_data)\n",
    "anime_df.head()\n",
    "anime_df.to_csv('./data/anime.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Vote</th>\n",
       "      <th>Ranked</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Status</th>\n",
       "      <th>Aired</th>\n",
       "      <th>Premiered</th>\n",
       "      <th>Producers</th>\n",
       "      <th>Licensors</th>\n",
       "      <th>Studios</th>\n",
       "      <th>Source</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sousou no FrierenFrieren: Beyond Journey's End</td>\n",
       "      <td>9.14</td>\n",
       "      <td>128768</td>\n",
       "      <td>1</td>\n",
       "      <td>508</td>\n",
       "      <td>28</td>\n",
       "      <td>Currently Airing</td>\n",
       "      <td>Sep 29, 2023 to Mar 2024</td>\n",
       "      <td>Fall 2023</td>\n",
       "      <td>[Aniplex, Dentsu, Shogakukan-Shueisha Producti...</td>\n",
       "      <td>None found, add some</td>\n",
       "      <td>Madhouse</td>\n",
       "      <td>Manga</td>\n",
       "      <td>24 min. per ep.</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>9.09</td>\n",
       "      <td>2080863</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Apr 5, 2009 to Jul 4, 2010</td>\n",
       "      <td>Spring 2009</td>\n",
       "      <td>[Aniplex, Square Enix, Mainichi Broadcasting S...</td>\n",
       "      <td>Funimation,       Aniplex of America</td>\n",
       "      <td>Bones</td>\n",
       "      <td>Manga</td>\n",
       "      <td>24 min. per ep.</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>9.07</td>\n",
       "      <td>1375512</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Apr 6, 2011 to Sep 14, 2011</td>\n",
       "      <td>Spring 2011</td>\n",
       "      <td>[Frontier Works, Media Factory, Kadokawa Shote...</td>\n",
       "      <td>Funimation</td>\n",
       "      <td>White Fox</td>\n",
       "      <td>Visual novel</td>\n",
       "      <td>24 min. per ep.</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GintamaÂ°Gintama Season 4</td>\n",
       "      <td>9.06</td>\n",
       "      <td>246431</td>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "      <td>51</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Apr 8, 2015 to Mar 30, 2016</td>\n",
       "      <td>Spring 2015</td>\n",
       "      <td>[TV Tokyo, Aniplex, Dentsu]</td>\n",
       "      <td>Funimation,       Crunchyroll</td>\n",
       "      <td>Bandai Namco Pictures</td>\n",
       "      <td>Manga</td>\n",
       "      <td>24 min. per ep.</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2Attack on Ti...</td>\n",
       "      <td>9.05</td>\n",
       "      <td>1545108</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Apr 29, 2019 to Jul 1, 2019</td>\n",
       "      <td>Spring 2019</td>\n",
       "      <td>[Production I.G, Dentsu, Mainichi Broadcasting...</td>\n",
       "      <td>Funimation</td>\n",
       "      <td>Wit Studio</td>\n",
       "      <td>Manga</td>\n",
       "      <td>23 min. per ep.</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Score     Vote Ranked  \\\n",
       "0     Sousou no FrierenFrieren: Beyond Journey's End  9.14   128768      1   \n",
       "1                   Fullmetal Alchemist: Brotherhood  9.09  2080863      2   \n",
       "2                                        Steins;Gate  9.07  1375512      3   \n",
       "3                           GintamaÂ°Gintama Season 4  9.06   246431      4   \n",
       "4  Shingeki no Kyojin Season 3 Part 2Attack on Ti...  9.05  1545108      5   \n",
       "\n",
       "  Popularity Episodes            Status                        Aired  \\\n",
       "0        508       28  Currently Airing     Sep 29, 2023 to Mar 2024   \n",
       "1          3       64   Finished Airing   Apr 5, 2009 to Jul 4, 2010   \n",
       "2         13       24   Finished Airing  Apr 6, 2011 to Sep 14, 2011   \n",
       "3        337       51   Finished Airing  Apr 8, 2015 to Mar 30, 2016   \n",
       "4         21       10   Finished Airing  Apr 29, 2019 to Jul 1, 2019   \n",
       "\n",
       "     Premiered                                          Producers  \\\n",
       "0    Fall 2023  [Aniplex, Dentsu, Shogakukan-Shueisha Producti...   \n",
       "1  Spring 2009  [Aniplex, Square Enix, Mainichi Broadcasting S...   \n",
       "2  Spring 2011  [Frontier Works, Media Factory, Kadokawa Shote...   \n",
       "3  Spring 2015                        [TV Tokyo, Aniplex, Dentsu]   \n",
       "4  Spring 2019  [Production I.G, Dentsu, Mainichi Broadcasting...   \n",
       "\n",
       "                              Licensors                Studios        Source  \\\n",
       "0                  None found, add some               Madhouse         Manga   \n",
       "1  Funimation,       Aniplex of America                  Bones         Manga   \n",
       "2                            Funimation              White Fox  Visual novel   \n",
       "3         Funimation,       Crunchyroll  Bandai Namco Pictures         Manga   \n",
       "4                            Funimation             Wit Studio         Manga   \n",
       "\n",
       "          Duration                          Rating  \n",
       "0  24 min. per ep.       PG-13 - Teens 13 or older  \n",
       "1  24 min. per ep.  R - 17+ (violence & profanity)  \n",
       "2  24 min. per ep.       PG-13 - Teens 13 or older  \n",
       "3  24 min. per ep.       PG-13 - Teens 13 or older  \n",
       "4  23 min. per ep.  R - 17+ (violence & profanity)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
